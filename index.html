<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Arc2Face: A Foundation Model of Human Faces">
  <meta name="keywords" content="Arc2Face, ID-embeddings, Stable Diffusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Arc2Face: A Foundation Model of Human Faces</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Arc2Face: A Foundation Model of Human Faces</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://foivospar.github.io/">Foivos Paraperas Papantoniou</a>,
            </span>
            <span class="author-block">
              <a href="https://alexlattas.com">Alexandros Lattas</a>,
            </span>
            <span class="author-block">
              <a href="https://moschoglou.com/">Stylianos Moschoglou</a>,
            </span>
            <span class="author-block">
              <a href="https://jiankangdeng.github.io/">Jiankang Deng</a>,
            </span>
            <span class="author-block">
              <a href="https://bernhard-kainz.com/">Bernhard Kainz</a>,
            </span>
            <span class="author-block">
              <a href="https://www.imperial.ac.uk/people/s.zafeiriou">Stefanos Zafeiriou</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Imperial College London, UK</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/foivospar/Arc2Face"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="hero-body">
      <div class="content has-text-justified">
        <p>
          <b>TL;DR</b>: We introduce a large dataset of high-resolution facial images with consistent ID and intra-class
          variability, and an ID-conditioned face model trained on it, which:<br>
          &nbsp;&nbsp;&nbsp;🔥 generates high-quality images of any subject given only its ArcFace embedding, within a few seconds<br>
          &nbsp;&nbsp;&nbsp;🔥 offers superior ID similarity compared to existing text-based models<br>
          &nbsp;&nbsp;&nbsp;🔥 is built on top of Stable Diffusion and can be extended to different input modalities, e.g. pose/expression
        </p>
      <video id="teaser" autoplay muted playsinline width="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper presents Arc2Face, an identity-conditioned face foundation model,
            which, given the ArcFace embedding of a person, can generate diverse photo-realistic
            images with an unparalleled degree of face similarity than existing models. Despite
            previous attempts to decode face recognition features into detailed images, we find
            that common high-resolution datasets (e.g. FFHQ) lack sufficient identities to reconstruct
            any subject. To that end, we meticulously upsample a significant portion of the WebFace42M
            database, the largest public dataset for face recognition (FR). Arc2Face builds upon a
            pretrained Stable Diffusion model, yet adapts it to the task of ID-to-face generation,
            conditioned solely on ID vectors. Deviating from recent works that combine ID with text
            embeddings for zero-shot personalization of text-to-image models, we emphasize on the
            compactness of FR features, which can fully capture the essence of the human face, as
            opposed to hand-crafted prompts. Crucially, text-augmented models struggle to decouple
            identity and text, usually necessitating some description of the given face to achieve
            satisfactory similarity. Arc2Face, however, only needs the discriminative features of
            ArcFace to guide the generation, offering a robust prior for a plethora of tasks where
            ID consistency is of paramount importance. As an example, we train a FR model on synthetic
            images from our model and achieve superior performance to existing synthetic datasets.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
    <!-- Method overview. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
        <p>
          We use a straightforward design to condition the pre-trained Stable Diffusion on ID features.
          The ArcFace embedding is processed by the text encoder using a
          frozen pseudo-prompt for compatibility, allowing projection into the CLIP latent space
          for cross-attention control. Both the encoder and UNet are optimized on a million-scale
          FR dataset (after upsampling), followed by additional fine-tuning on high-quality
          datasets, without any text annotations.
        </p>
        <div>
            <img src="./static/images/pipeline.jpg" alt="method" class="center">
          </div>
        <p>
          Through extensive fine-tuning, we effectively transform the text encoder into a face encoder
          specifically tailored for projecting ArcFace embeddings into the CLIP latent space.
          The resulting model exclusively adheres to ID-embeddings, disregarding its initial language guidance.
        </p>
          </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
  <!-- Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">ID-consistent generation</h2>
         <div class="content has-text-centered">
         <div>
             <img src="./static/images/samples.jpg" class="center">
         </div>
         <p>
             Given the ID-embedding as input, Arc2Face can generate diverse, realistic images of any subject with state-of-the-art ID retention.
         </p>
     </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
  <!-- Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Arc2Face + ControlNet</h2>
         <div class="content has-text-centered">
         <div>
             <img src="./static/images/controlnet.jpg" class="center">
         </div>
         <p>
           We can additionally control the pose/expression using a 3DMM.
         </p>
     </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
  <!-- Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Comparison with text-based methods</h2>
         <div class="content has-text-centered">
         <div>
             <img src="./static/images/comp.jpg" class="center">
         </div>
         <p>
             Text-augmented methods achieve impressive stylizations, however they require detailed prompts.
             We evaluate their ID-conditioning ability using the abstract prompt “photo of a person”.
         </p>
     </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code></code></pre>
  </div>
</section>


<footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              The source code of this website is borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
